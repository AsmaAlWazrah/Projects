{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import libarchive\n",
    "import pydot\n",
    "import cartopy\n",
    "import re\n",
    "import sys\n",
    "import codecs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "#from nltk.stem.arlstem import ARLSTem\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import keras_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56674, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قبل ان يتحلطم عبيد الدنيا بسبب رفع_الدعم لابد...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>اكثر الساخطين على قرار رفع_اسعار_البنزين_والك...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وبعد فتره من تطبيق رسوم_الاراضي_البيضاا سوف ي...</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اذاخسر تعادل الهلال حطوا بيضه فوق راسي وتجيكم ...</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اخطاا كثيره اليوم من لاعبي الهلال بالاخص سلمان...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Polarity\n",
       "0   قبل ان يتحلطم عبيد الدنيا بسبب رفع_الدعم لابد...      pos\n",
       "1   اكثر الساخطين على قرار رفع_اسعار_البنزين_والك...      neg\n",
       "2   وبعد فتره من تطبيق رسوم_الاراضي_البيضاا سوف ي...     neut\n",
       "3  اذاخسر تعادل الهلال حطوا بيضه فوق راسي وتجيكم ...     neut\n",
       "4  اخطاا كثيره اليوم من لاعبي الهلال بالاخص سلمان...      neg"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Desktop/a.csv')\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "print(data.shape)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1453f47e588>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Polarity'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1452fccff28>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Tweet'].str.len().plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قبل ان يتحلطم عبيد الدنيا بسبب رفع_الدعم لابد...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>اكثر الساخطين على قرار رفع_اسعار_البنزين_والك...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وبعد فتره من تطبيق رسوم_الاراضي_البيضاا سوف ي...</td>\n",
       "      <td>neut</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اذاخسر تعادل الهلال حطوا بيضه فوق راسي وتجيكم ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اخطاا كثيره اليوم من لاعبي الهلال بالاخص سلمان...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Polarity  Sentiment\n",
       "0   قبل ان يتحلطم عبيد الدنيا بسبب رفع_الدعم لابد...      pos          1\n",
       "1   اكثر الساخطين على قرار رفع_اسعار_البنزين_والك...      neg          0\n",
       "2   وبعد فتره من تطبيق رسوم_الاراضي_البيضاا سوف ي...     neut          2\n",
       "3  اذاخسر تعادل الهلال حطوا بيضه فوق راسي وتجيكم ...     neut          2\n",
       "4  اخطاا كثيره اليوم من لاعبي الهلال بالاخص سلمان...      neg          0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(x):\n",
    "    if x == 'neg':\n",
    "        return 0\n",
    "    elif x == 'pos':\n",
    "        return 1\n",
    "    return 2\n",
    "data['Sentiment'] = data['Polarity'].apply(transform)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قبل ان يتحلطم عبيد الدنيا بسبب رفع_الدعم لابد...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>[يتحلطم, عبيد, الدنيا, بسب, رفع, لابد, نتذكر, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>اكثر الساخطين على قرار رفع_اسعار_البنزين_والك...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>[الساخطين, قرار, رفع, خرفان, لديهم, ارتباطات, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وبعد فتره من تطبيق رسوم_الاراضي_البيضاا سوف ي...</td>\n",
       "      <td>neut</td>\n",
       "      <td>2</td>\n",
       "      <td>[وبعد, فتره, تطبيق, رسوم, يتمكن, باءع, الارض, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اذاخسر تعادل الهلال حطوا بيضه فوق راسي وتجيكم ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>2</td>\n",
       "      <td>[اذاخسر, تعادل, الهلال, حطوا, بيضه, راسي, وتجي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اخطاا كثيره اليوم من لاعبي الهلال بالاخص سلمان...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>[اخطا, كثيره, لاعبي, الهلال, بالاخص, سلمان, ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>والله لو كان سكان غزه من غير المسلمين بل لو ك...</td>\n",
       "      <td>neut</td>\n",
       "      <td>2</td>\n",
       "      <td>[واله, سكان, غزه, المسلمين, كانوا, ليسوا, البش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>رفع_اسعار_البنزين_والكهرباا ي حسرتي ي وجودي م...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>[رفع, حسرتي, وجودي, ماعاد, فره]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>الحمدلله على عطائه الحمدلله على نعمه التي لا ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>[الحمدله, عطاءه, الحمدله, نعمه, تعد, تحصي, غير...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ابطالنا يسطرون الملاحم بشجاعه وبساله اللهم ثب...</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>[ابطالنا, يسطرون, الملاحم, بشجاعه, وبساله, اله...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>الحين ليش تغردون اصلا انا غايب غايب تعليق_الدر...</td>\n",
       "      <td>neut</td>\n",
       "      <td>2</td>\n",
       "      <td>[الحين, ليش, تغردون, اصلا, انا, غايب, غايب, تع...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Polarity  Sentiment  \\\n",
       "0   قبل ان يتحلطم عبيد الدنيا بسبب رفع_الدعم لابد...      pos          1   \n",
       "1   اكثر الساخطين على قرار رفع_اسعار_البنزين_والك...      neg          0   \n",
       "2   وبعد فتره من تطبيق رسوم_الاراضي_البيضاا سوف ي...     neut          2   \n",
       "3  اذاخسر تعادل الهلال حطوا بيضه فوق راسي وتجيكم ...     neut          2   \n",
       "4  اخطاا كثيره اليوم من لاعبي الهلال بالاخص سلمان...      neg          0   \n",
       "5   والله لو كان سكان غزه من غير المسلمين بل لو ك...     neut          2   \n",
       "6   رفع_اسعار_البنزين_والكهرباا ي حسرتي ي وجودي م...      neg          0   \n",
       "7   الحمدلله على عطائه الحمدلله على نعمه التي لا ...      pos          1   \n",
       "8   ابطالنا يسطرون الملاحم بشجاعه وبساله اللهم ثب...      pos          1   \n",
       "9  الحين ليش تغردون اصلا انا غايب غايب تعليق_الدر...     neut          2   \n",
       "\n",
       "                                               clean  \n",
       "0  [يتحلطم, عبيد, الدنيا, بسب, رفع, لابد, نتذكر, ...  \n",
       "1  [الساخطين, قرار, رفع, خرفان, لديهم, ارتباطات, ...  \n",
       "2  [وبعد, فتره, تطبيق, رسوم, يتمكن, باءع, الارض, ...  \n",
       "3  [اذاخسر, تعادل, الهلال, حطوا, بيضه, راسي, وتجي...  \n",
       "4  [اخطا, كثيره, لاعبي, الهلال, بالاخص, سلمان, ال...  \n",
       "5  [واله, سكان, غزه, المسلمين, كانوا, ليسوا, البش...  \n",
       "6                    [رفع, حسرتي, وجودي, ماعاد, فره]  \n",
       "7  [الحمدله, عطاءه, الحمدله, نعمه, تعد, تحصي, غير...  \n",
       "8  [ابطالنا, يسطرون, الملاحم, بشجاعه, وبساله, اله...  \n",
       "9  [الحين, ليش, تغردون, اصلا, انا, غايب, غايب, تع...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove users\n",
    "data['clean'] = data['Tweet'].apply(lambda x: re.sub('(@[A-Za-z]+)', '', x, flags=re.UNICODE))\n",
    "\n",
    "#remove hashtags\n",
    "data['clean'] = data['clean'].apply(lambda x: re.sub('(#[أ-ي]+)|(_[أ-ي]+)', '', x, flags=re.UNICODE))\n",
    "\n",
    "#remove letters, numbers & symbols\n",
    "data['clean'] = data['clean'].apply(lambda x: re.sub('[a-zA-Z0-9@=$:.،%^*\"#~£/&\\n؟?!-_]', '', x, flags=re.UNICODE))\n",
    "\n",
    "#arabic numbers\n",
    "data['clean'] = data['clean'].apply(lambda x: re.sub('[٠١٢٣٤٥٦٧٨٩]', '', x, flags=re.UNICODE))\n",
    "\n",
    "#nltk tokenize\n",
    "data['clean'].apply(word_tokenize)\n",
    "data['clean'] = data['clean'].apply(word_tokenize) \n",
    "\n",
    "#repeated letters\n",
    "data['clean']= data['clean'].apply(lambda x: [''.join(ch for ch, _ in itertools.groupby(y)) for y in x])\n",
    "\n",
    "#normalization\n",
    "def normalizeArabic(text):\n",
    "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"و\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    return(text)\n",
    "data['clean']= data['clean'].apply(lambda x: [normalizeArabic(y) for y in x])\n",
    "\n",
    "#remove stopwords\n",
    "def get_stop_words():\n",
    "    path = 'list.txt'\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "\n",
    "stop_words = get_stop_words()\n",
    "data['clean']= data['clean'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "#remove emojis\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "data['clean']= data['clean'].apply(lambda x: [remove_emoji(y) for y in x])\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBOW = Word2Vec.load('../Desktop/aravecuni/full_uni_cbow_100_twitter.mdl')\n",
    "CBOWE = CBOW.wv.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildWordVector(tokens, size):\n",
    "#     vec = np.zeros(size).reshape((1, size))\n",
    "#     count = 0.\n",
    "#     for word in tokens:\n",
    "#         try:\n",
    "#             vec += CBOW[word].reshape((1, size))\n",
    "#             count += 1.\n",
    "#         except KeyError: # handling the case where the token is not\n",
    "#             continue\n",
    "#     if count != 0:\n",
    "#         vec /= count\n",
    "#     return vec\n",
    "\n",
    "# X_train = np.concatenate([buildWordVector(x, 100) for x in data['clean']])\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(data['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,   761,  6231, 35366,  3894,  9821,    46],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0, 18406,\n",
       "        18407, 14922,  8799, 18408, 18409, 14923, 18410, 18411, 18412,\n",
       "        12770,  1725, 14924,  3713, 12771, 18413, 18414],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,  1122,     1, 35367],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,    94,   194,  1086,   443,   762,     1, 12772,\n",
       "         7952, 14925,   186, 23980,   970, 18415,     1],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     1,   120,    60,\n",
       "         3530,   278,  1024,   537,  3530, 12773,  1024]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(data['clean']), split=\" \")\n",
    "tokenizer.fit_on_texts(data['clean'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['clean'].values)\n",
    "X = pad_sequences(X) # padding our text vector so they all have the same length\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56674, 25)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# calculate f score\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asma Al Wazrah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    keras_metrics.precision(),\n",
    "    keras_metrics.recall(),\n",
    "    f1,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparamters\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "VALIDATION_SPLIT = 0.3\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Build the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "WARNING:tensorflow:From C:\\Users\\Asma Al Wazrah\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asma Al Wazrah\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 39671 samples, validate on 17003 samples\n",
      "Epoch 1/10\n",
      "39671/39671 [==============================] - 44s 1ms/step - loss: 0.8554 - acc: 0.6051 - precision: 0.6583 - recall: 0.4768 - f1: 0.5343 - val_loss: 0.7496 - val_acc: 0.6734 - val_precision: 0.6735 - val_recall: 0.6752 - val_f1: 0.644029 - precision: 0.6564 - recall: \n",
      "Epoch 2/10\n",
      "39671/39671 [==============================] - 43s 1ms/step - loss: 0.6630 - acc: 0.7232 - precision: 0.7476 - recall: 0.6747 - f1: 0.7067 - val_loss: 0.6966 - val_acc: 0.7045 - val_precision: 0.7174 - val_recall: 0.6721 - val_f1: 0.6893\n",
      "Epoch 3/10\n",
      "39671/39671 [==============================] - 44s 1ms/step - loss: 0.5639 - acc: 0.7715 - precision: 0.7932 - recall: 0.7365 - f1: 0.7625 - val_loss: 0.7111 - val_acc: 0.7105 - val_precision: 0.7032 - val_recall: 0.7276 - val_f1: 0.7045\n",
      "Epoch 4/10\n",
      "39671/39671 [==============================] - 44s 1ms/step - loss: 0.4818 - acc: 0.8114 - precision: 0.8297 - recall: 0.7887 - f1: 0.8071 - val_loss: 0.7243 - val_acc: 0.7088 - val_precision: 0.7683 - val_recall: 0.6133 - val_f1: 0.7019\n",
      "Epoch 5/10\n",
      "39671/39671 [==============================] - 44s 1ms/step - loss: 0.4100 - acc: 0.8441 - precision: 0.8617 - recall: 0.8285 - f1: 0.8412 - val_loss: 0.7711 - val_acc: 0.7096 - val_precision: 0.7347 - val_recall: 0.6752 - val_f1: 0.7065\n",
      "Epoch 6/10\n",
      "39671/39671 [==============================] - 44s 1ms/step - loss: 0.3477 - acc: 0.8662 - precision: 0.8837 - recall: 0.8558 - f1: 0.8652 - val_loss: 0.8467 - val_acc: 0.7048 - val_precision: 0.6880 - val_recall: 0.7284 - val_f1: 0.7019\n",
      "Epoch 7/10\n",
      "39671/39671 [==============================] - 43s 1ms/step - loss: 0.2951 - acc: 0.8882 - precision: 0.9022 - recall: 0.8809 - f1: 0.8873 - val_loss: 0.9053 - val_acc: 0.6993 - val_precision: 0.7485 - val_recall: 0.6236 - val_f1: 0.6988\n",
      "Epoch 8/10\n",
      "39671/39671 [==============================] - 43s 1ms/step - loss: 0.2518 - acc: 0.9068 - precision: 0.9170 - recall: 0.9018 - f1: 0.9063 - val_loss: 0.9386 - val_acc: 0.7001 - val_precision: 0.6936 - val_recall: 0.7188 - val_f1: 0.6985\n",
      "Epoch 9/10\n",
      "39671/39671 [==============================] - 44s 1ms/step - loss: 0.2148 - acc: 0.9210 - precision: 0.9312 - recall: 0.9179 - f1: 0.9209 - val_loss: 1.0194 - val_acc: 0.7003 - val_precision: 0.6985 - val_recall: 0.7032 - val_f1: 0.7007\n",
      "Epoch 10/10\n",
      "39671/39671 [==============================] - 43s 1ms/step - loss: 0.1891 - acc: 0.9316 - precision: 0.9384 - recall: 0.9288 - f1: 0.9315 - val_loss: 1.1067 - val_acc: 0.7016 - val_precision: 0.7165 - val_recall: 0.6726 - val_f1: 0.6996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1452bf55b70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "lstm_model_input = layers.Input(shape=(X.shape[1],))\n",
    "x = CBOWE(lstm_model_input)\n",
    "x = layers.LSTM(100, return_sequences=True)(x)\n",
    "x = layers.LSTM(100, return_sequences=False)(x)\n",
    "x = layers.Dropout(.5)(x)\n",
    "x = layers.Dense(3, activation='softmax')(x)\n",
    "lstm_model = keras.models.Model(inputs=lstm_model_input, outputs=x)\n",
    "\n",
    "lstm_model.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "                   metrics=metrics,)\n",
    "lstm_model.fit(X, y, \n",
    "               validation_split=VALIDATION_SPLIT, \n",
    "               batch_size=BATCH_SIZE, \n",
    "               epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('../Desktop/stacked-lstm-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 25, 100)           125975600 \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 126,136,703\n",
      "Trainable params: 161,103\n",
      "Non-trainable params: 125,975,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-a28c71a07a91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When feeding symbolic tensors to a model, we expect thetensors to have a static batch size. Got tensor with shape: (None, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-31176e6ad5be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                epochs=EPOCHS)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;34m'When feeding symbolic tensors to a model, we expect the'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;34m'tensors to have a static batch size. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When feeding symbolic tensors to a model, we expect thetensors to have a static batch size. Got tensor with shape: (None, 3)"
     ]
    }
   ],
   "source": [
    "%time\n",
    "gru_model_input = layers.Input(shape=(X.shape[1],))\n",
    "x = CBOWE(gru_model_input)\n",
    "x = layers.GRU(100, return_sequences=True)(x)\n",
    "x = layers.GRU(100, return_sequences=False)(x)\n",
    "x = layers.Dropout(.5)(x)\n",
    "x = layers.Dense(3, activation='softmax')(x)\n",
    "gru_model = keras.models.Model(inputs=gru_model_input, outputs=x)\n",
    "\n",
    "gru_model.compile(loss='categorical_crossentropy', \n",
    "                   optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "                   metrics=metrics,)\n",
    "gru_model.fit(X, y, \n",
    "               validation_split=VALIDATION_SPLIT, \n",
    "               batch_size=BATCH_SIZE, \n",
    "               epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      multiple                  125975600 \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 25, 100)           60300     \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 100)               60300     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 126,096,503\n",
      "Trainable params: 120,903\n",
      "Non-trainable params: 125,975,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.save('../Desktop/stacked-gru-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
